{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to importing data with Python\n",
    "\n",
    "1. **Variety of Data Sources**:\n",
    "   - Flat files like .txt and .csv.\n",
    "   - Files native to other software i.e., Excel spreadsheets and files from Stata, SAS, and MATLAB.\n",
    "   - Relational databases including SQLite and PostgreSQL.\n",
    "\n",
    "2. **Classification of Text Files**:\n",
    "   - Plain text files, for example, literary works like excerpts from Mark Twain's \"The Adventures of Huckleberry Finn\".\n",
    "   - Structured data text files like \"titanic.csv\", where each row represents an individual (such as a passenger) and each column denotes attributes like gender, cabin, and survival status.\n",
    "\n",
    "3. **Reading and Handling Text Files**:\n",
    "   - Basic file reading using Python's `open` function with mode 'r' for read-only access, ensuring you don’t accidentally modify the file.\n",
    "   - Importance of closing the file connection after reading, using `file.close()`.\n",
    "   - Best practices like using the context manager (`with` statement) to automatically handle file closing.\n",
    "\n",
    "   - How to display the contents of a file in the console using `print()`.\n",
    "   - Different file access modes, with a mention of mode 'w' for writing to files, though not focused on in this course.\n",
    "4. **Enhanced File Management**:\n",
    "   - Introduction to using context managers for optimal file management, ensuring files are closed post-operations.\n",
    "   - Interactive exercises will include tasks like printing file contents and specific lines, useful for managing large files.\n",
    "\n",
    "5. **Using NumPy for Efficient Data Handling**:\n",
    "   - An introduction to the Python library NumPy to facilitate the import and management of numerical data from flat files.\n",
    "\n",
    "These points provide a comprehensive overview of the necessary skills for importing and managing various data file types using Python, focusing on practical methods and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dealing with flat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Reading a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name= \"sample.txt\"\n",
    "# file= open(file_name, mode=\"r\")\n",
    "file= open(file_name, \"r\")\n",
    "txt= file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to the phase 2 of data analysis! I am your trainer Zartashia Afzal.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the phase 2 of data analysis! I am your trainer Zartashia Afzal.\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name= \"sample.txt\"\n",
    "file = open(file_name, mode='w')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context manager with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('sample.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice**\n",
    "\n",
    "-   Open the txt file as read-only.\n",
    "-   Print the contents.\n",
    "-   Check whether the file is closed.\n",
    "-   Close the file.\n",
    "-   Check again that the file is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Open a file: file\n",
    "file = open(\"sample.txt\", mode=\"r\")\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    "\n",
    "# Close file\n",
    "\n",
    "file.close()\n",
    "# Check whether file is closed\n",
    "\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing text files linewise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zen of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data with NumPy\n",
    "\n",
    "-   NumPy is essential for numerical data handling in Python.\n",
    "-   Use `loadtxt()` or `genfromtxt()` for importing numerical datasets, like MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('mnist.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Importing Flat Files with NumPy\n",
    "- Brief overview of opening text files using Python's built-in `open` function.\n",
    "- Introduction to using NumPy for importing numerical data into numpy arrays.\n",
    "- Benefits of using numpy arrays: efficiency, speed, and clean data handling.\n",
    "\n",
    "# Why Use NumPy?\n",
    "- NumPy arrays as the Python standard for numerical data storage.\n",
    "- Importance for other Python packages, like scikit-learn.\n",
    "- Built-in functions in NumPy like `loadtxt` and `genfromtxt` facilitate efficient data import.\n",
    "\n",
    "# Basic Import with NumPy\n",
    "- How to import NumPy: `import numpy as np`\n",
    "- Using `np.loadtxt` to load flat files: requires filename and delimiter.\n",
    "- Setting the delimiter: Default is whitespace, often needs to be specified.\n",
    "\n",
    "# Customizing NumPy Import\n",
    "- Optional parameters to better control data import:\n",
    "  - `skiprows` to skip header rows, e.g., `skiprows=1`.\n",
    "  - `usecols` to specify which columns to import, e.g., `usecols=[0, 2]`.\n",
    "\n",
    "# Handling Different DataTypes\n",
    "- Using `dtype` parameter to specify data types, e.g., `dtype='str'` for importing all strings.\n",
    "- Challenges with mixed data types in flat files.\n",
    "- Example of issues: Importing complex datasets like the Titanic dataset with both floats and strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data with Pandas\n",
    "\n",
    "Pandas provides a powerful DataFrame object, which is ideal for handling labeled data with columns of potentially different types. Here’s how to import data using pandas:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Files in Practice\n",
    "\n",
    "Flat files like `.csv` are widely used for simple and straightforward data storage. They represent data in rows and columns, making them easy to process and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why does to identify type syntax is written as # Print datatype of digits**\n",
    "**print(type(digits)) and not like this: print(digits.type()).**\n",
    " \n",
    " The way types are identified in Python reflects its design philosophy and structural decisions. In Python, the syntax `print(type(digits))` is used to determine the type of an object like `digits` for a few key reasons:\n",
    "\n",
    "1. **Built-in `type()` Function**: Python uses the built-in function `type()` to return the type of an object. The syntax `type(object)` is consistent with other built-in functions like `len()` for length and `id()` for identity, which also follow the pattern of `function(argument)`. This consistency makes Python intuitive and predictable.\n",
    "\n",
    "2. **Separation of Data and Operations**: In Python, types are not bound as methods to the objects. This design decision means that objects like integers, strings, or lists do not carry their type-checking methods. Instead, such functionalities are implemented through external functions (like `type()`) or in specific methods bound to all objects (like `__class__`). This separation helps keep objects lightweight and minimizes redundancy in method definitions across different types.\n",
    "\n",
    "3. **Python’s Dynamic Typing**: Python is a dynamically typed language, meaning that the type of a variable is determined at runtime. This dynamic nature is why a separate function like `type()` is more suitable. It can be applied to any variable at any point in its lifecycle, regardless of its current type, enhancing flexibility.\n",
    "\n",
    "4. **Object-Oriented Approach**: The syntax `print(digits.type())` implies that `type` would be a method specific to the `digits` object. However, in Python, not every object needs to define its own method to reveal its type; instead, the universal `type()` function queries an object for its type. This approach adheres to Python's philosophy of simple, readable code that can be universally applied.\n",
    "\n",
    "In essence, `type(object)` as a function call is an example of Python's approach to providing utilities that are general and can be used across all types of objects, making the language easy to learn and use while maintaining a clear and consistent syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Complete the first call to np.loadtxt() by passing file as the first argument.\n",
    "-   Execute print(data[0]) to print the first element of data.\n",
    "-   Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row.\n",
    "-   Print the 10th element of data_float by completing the print() command. Be guided by the previous print() call.\n",
    "-   Execute the rest of the code to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    "\n",
    "# Import file: data using np_load\n",
    "data = \n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    "\n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = \n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(____)\n",
    "\n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()\n",
    "\n",
    "#  **`plt.scatter(data_float[:, 0], data_float[:, 1])`**:\n",
    "# - `data_float[:, 0]`: This part of the code is indexing a multidimensional array named `data_float`. The `[:, 0]` part means \"select all rows from the first column\". This is likely the x-axis data for the scatterplot.\n",
    "# - `data_float[:, 1]`: Similarly, this indexes the second column of the `data_float` array, selecting all rows from this column. This represents the y-axis data for the scatterplot.\n",
    "\n",
    "# The code essentially takes a dataset (`data_float`) which appears to be in the form of a 2D array, and plots the first column of the array against the second column as points in a scatterplot. Each point in the scatterplot represents one row of the dataset, with its respective values from the first and second columns determining its position on the x-axis and y-axis, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes\n",
    "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function `np.loadtxt()` will freak at this. There is another function, `np.genfromtxt()`, which can handle such structures. If we pass `dtype=None` to it, it will figure out what types each column should be.\n",
    "\n",
    "-   Import 'titanic.csv' using the function np.genfromtxt()\n",
    "-   print the entire column with the name Survived. What are the last 4 values of this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_22604\\3771359666.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt('titanic.csv', delimiter=\",\", names=True, dtype=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  There is also another function `np.recfromcsv()` that behaves similarly to np.genfromtxt(), except that its default dtype is None\n",
    "\n",
    "-   Import titanic.csv using the function np.recfromcsv() and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None!\n",
    "-   Run the remaining code to print the first three entries of the resulting array d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the filename: file\n",
    "file = 'titanic.csv'\n",
    "\n",
    "# Import file using np.recfromcsv: d\n",
    "d=np.recfromcsv(file)\n",
    "\n",
    "# Print out first three entries of d\n",
    "print(d[:3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
